{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "666e482c",
   "metadata": {},
   "source": [
    "# Bayesian Estimation of Prospect Theory Parameters\n",
    "This notebook builds a PyMC model to estimate parameters of a decision-making model using behavioral data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89c9ce70",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pymc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpymc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpm\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pymc'"
     ]
    }
   ],
   "source": [
    "import pymc as pm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import aesara.tensor as at\n",
    "import arviz as az\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a5b603",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493d0d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your dataset here\n",
    "# It should have columns: invest, potential_gain, potential_loss, probability_win_percent, probability_loss_percent\n",
    "\n",
    "# Example (you should replace this with real data loading)\n",
    "data = pd.read_csv(\"your_data.csv\")\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9dc599",
   "metadata": {},
   "source": [
    "## Define Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768f9d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_eta(green, red, theta):\n",
    "    return at.clip(green + (1 - green - red) * theta, 0, 1)\n",
    "\n",
    "def calc_subj_prob(p, gamma):\n",
    "    return (p ** gamma) / ((p ** gamma + (1 - p) ** gamma) ** (1 / gamma))\n",
    "\n",
    "def calc_subj_values(x, Lambda, alpha, beta):\n",
    "    return at.switch(x >= 0, x ** alpha, -Lambda * ((-x) ** beta))\n",
    "\n",
    "def pt_utility(gain, loss, p_win, p_loss, theta, Lambda, alpha, beta, gamma):\n",
    "    eta_gain = calc_eta(p_win, p_loss, theta)\n",
    "    eta_loss = calc_eta(p_loss, p_win, 1 - theta)\n",
    "    v_gain = calc_subj_values(gain, Lambda, alpha, beta)\n",
    "    v_loss = calc_subj_values(-loss, Lambda, alpha, beta)\n",
    "    pi_gain = calc_subj_prob(eta_gain, gamma)\n",
    "    pi_loss = calc_subj_prob(eta_loss, gamma)\n",
    "    return v_gain * pi_gain + v_loss * pi_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9fd92c",
   "metadata": {},
   "source": [
    "## Build and Sample the Bayesian Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9625f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as model:\n",
    "    # Priors\n",
    "    theta = pm.Lognormal('theta', mu=0, sigma=1)\n",
    "    Lambda = pm.Lognormal('Lambda', mu=0, sigma=1)\n",
    "    tau = pm.Lognormal('tau', mu=0, sigma=1)\n",
    "    alpha = pm.Lognormal('alpha', mu=0, sigma=1)\n",
    "    beta = pm.Lognormal('beta', mu=0, sigma=1)\n",
    "    gamma = pm.Lognormal('gamma', mu=0, sigma=1)\n",
    "    error = pm.Normal('error', mu=0, sigma=1)\n",
    "\n",
    "    # Data\n",
    "    gain = pm.Data('gain', data['potential_gain'])\n",
    "    loss = pm.Data('loss', data['potential_loss'])\n",
    "    p_win = pm.Data('p_win', data['probability_win_percent'])\n",
    "    p_loss = pm.Data('p_loss', data['probability_loss_percent'])\n",
    "    invest = pm.Data('invest', data['invest'])\n",
    "\n",
    "    # Model logic\n",
    "    utility = pt_utility(gain, loss, p_win, p_loss, theta, Lambda, alpha, beta, gamma)\n",
    "    prob = pm.Deterministic('prob', 1 / (1 + at.exp(-tau * (utility - error))))\n",
    "\n",
    "    # Likelihood\n",
    "    y_obs = pm.Bernoulli('y_obs', p=prob, observed=invest)\n",
    "\n",
    "    # Sampling\n",
    "    trace = pm.sample(2000, tune=1000, target_accept=0.95, return_inferencedata=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f4fd41",
   "metadata": {},
   "source": [
    "## Posterior Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d673700f",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_trace(trace)\n",
    "az.summary(trace, round_to=2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mgme_task",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
